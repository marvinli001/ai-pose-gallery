"""
AIæœåŠ¡ - å›¾ç‰‡åˆ†æå’Œæ ‡ç­¾ç”Ÿæˆ
"""
import base64
import httpx
from typing import List, Dict, Any
from PIL import Image
import io
import json

from app.config import get_settings
from app.models.image import TagCategory

settings = get_settings()


class AIService:
    """AIæœåŠ¡ç±»"""
    
    def __init__(self):
        self.client = httpx.AsyncClient()
        
    async def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """åˆ†æå›¾ç‰‡å¹¶ç”Ÿæˆæ ‡ç­¾å’Œæè¿°"""
        try:
            # åŠ è½½å’Œå¤„ç†å›¾ç‰‡
            image_data = self._prepare_image(image_path)
            
            # å¦‚æœæ²¡æœ‰é…ç½®OpenAI API Keyï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ
            if not settings.openai_api_key or settings.openai_api_key == "your_openai_api_key_here":
                return self._mock_analysis(image_path)
            
            # è°ƒç”¨OpenAI Vision API
            return await self._call_openai_vision(image_data)
            
        except Exception as e:
            print(f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
            return self._get_fallback_analysis()
    
    def _prepare_image(self, image_path: str) -> str:
        """å‡†å¤‡å›¾ç‰‡æ•°æ®ç”¨äºAIåˆ†æ"""
        try:
            # æ‰“å¼€å›¾ç‰‡
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGB
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # è°ƒæ•´å¤§å°ä»¥èŠ‚çœAPIè´¹ç”¨
                max_size = 1024
                if img.width > max_size or img.height > max_size:
                    img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                
                # è½¬æ¢ä¸ºbase64
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                image_bytes = buffer.getvalue()
                
                return base64.b64encode(image_bytes).decode('utf-8')
                
        except Exception as e:
            print(f"âŒ å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _call_openai_vision(self, image_data: str) -> Dict[str, Any]:
        """è°ƒç”¨OpenAI Vision API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {settings.openai_api_key}"
        }
        
        prompt = """è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„äººç‰©å§¿åŠ¿å’Œåœºæ™¯ï¼Œå¹¶æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹ï¼ˆ100å­—ä»¥å†…ï¼‰
2. æå–ç›¸å…³æ ‡ç­¾ï¼ŒåŒ…æ‹¬ï¼š
   - å§¿åŠ¿ç±»å‹ï¼ˆå¦‚ï¼šç«™å§¿ã€åå§¿ã€èººå§¿ã€è¹²å§¿ï¼‰
   - æ€§åˆ«ï¼ˆå¦‚ï¼šç”·æ€§ã€å¥³æ€§ï¼‰
   - å¹´é¾„æ®µï¼ˆå¦‚ï¼šå„¿ç«¥ã€é’å¹´ã€ä¸­å¹´ã€è€å¹´ï¼‰
   - æœè£…ï¼ˆå¦‚ï¼šæ­£è£…ã€ä¼‘é—²è£…ã€è£™å­ï¼‰
   - é“å…·ï¼ˆå¦‚ï¼šæ¤…å­ã€æ¡Œå­ã€ä¹¦æœ¬ã€å’–å•¡æ¯ã€æ— é“å…·ï¼‰
   - åœºæ™¯ï¼ˆå¦‚ï¼šå®¤å†…ã€æˆ·å¤–ã€åŠå…¬å®¤ã€å®¶å±…ï¼‰
   - å…‰çº¿ï¼ˆå¦‚ï¼šè‡ªç„¶å…‰ã€äººå·¥å…‰ã€æŸ”å’Œå…‰ã€å¼ºå…‰ï¼‰
   - è§’åº¦ï¼ˆå¦‚ï¼šæ­£é¢ã€ä¾§é¢ã€èƒŒé¢ã€ä¿¯è§†ã€ä»°è§†ï¼‰
   - è¡¨æƒ…ï¼ˆå¦‚ï¼šå¾®ç¬‘ã€ä¸¥è‚ƒã€æ€è€ƒã€æ”¾æ¾ï¼‰
   - åŠ¨ä½œï¼ˆå¦‚ï¼šç«™ç«‹ã€è¡Œèµ°ã€é˜…è¯»ã€æ€è€ƒã€ä¼¸å±•ï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
    "description": "å›¾ç‰‡æè¿°",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", ...],
    "confidence": 0.85
}"""

        payload = {
            "model": "gpt-4-vision-preview",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 500
        }
        
        try:
            response = await self.client.post(
                f"{settings.openai_base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30.0
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                # å°è¯•è§£æJSON
                try:
                    analysis = json.loads(content)
                    return analysis
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                    return self._parse_text_response(content)
            else:
                print(f"âŒ OpenAI APIé”™è¯¯: {response.status_code} - {response.text}")
                return self._get_fallback_analysis()
                
        except Exception as e:
            print(f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return self._get_fallback_analysis()
    
    def _mock_analysis(self, image_path: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸAIåˆ†æï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        print("ğŸ¤– ä½¿ç”¨æ¨¡æ‹ŸAIåˆ†æï¼ˆæœªé…ç½®OpenAI API Keyï¼‰")
        
        import random
        from pathlib import Path
        
        filename = Path(image_path).name.lower()
        
        # æ ¹æ®æ–‡ä»¶åæ¨æµ‹å†…å®¹
        tags = []
        description = "äººç‰©å§¿åŠ¿å‚è€ƒå›¾ç‰‡"
        
        # åŸºç¡€æ ‡ç­¾
        tags.extend(random.choices(["å¥³æ€§", "ç”·æ€§"], k=1))
        tags.extend(random.choices(["é’å¹´", "ä¸­å¹´"], k=1))
        tags.extend(random.choices(["ç«™å§¿", "åå§¿", "èººå§¿"], k=1))
        tags.extend(random.choices(["æ­£é¢", "ä¾§é¢", "èƒŒé¢"], k=1))
        tags.extend(random.choices(["å®¤å†…", "æˆ·å¤–"], k=1))
        tags.extend(random.choices(["è‡ªç„¶å…‰", "äººå·¥å…‰"], k=1))
        tags.extend(random.choices(["ä¼‘é—²è£…", "æ­£è£…"], k=1))
        
        # æ ¹æ®æ–‡ä»¶åæ·»åŠ ç‰¹å®šæ ‡ç­¾
        if any(word in filename for word in ["sit", "chair", "å"]):
            tags.append("åå§¿")
            tags.append("æ¤…å­")
            description = "äººç‰©åå§¿å‚è€ƒï¼Œé€‚åˆæ’ç”»å’Œæ‘„å½±å‚è€ƒ"
        elif any(word in filename for word in ["stand", "ç«™"]):
            tags.append("ç«™å§¿")
            description = "äººç‰©ç«™å§¿å‚è€ƒï¼Œå±•ç°è‡ªç„¶ç«™ç«‹å§¿æ€"
        
        if any(word in filename for word in ["outdoor", "park", "æˆ·å¤–"]):
            tags.extend(["æˆ·å¤–", "è‡ªç„¶å…‰"])
            description += "ï¼Œæˆ·å¤–ç¯å¢ƒæ‹æ‘„"
        
        # å»é‡
        tags = list(set(tags))
        
        return {
            "description": description,
            "tags": tags[:8],  # æœ€å¤š8ä¸ªæ ‡ç­¾
            "confidence": round(random.uniform(0.75, 0.95), 2)
        }
    
    def _parse_text_response(self, content: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬å“åº”ä¸­è§£æåˆ†æç»“æœ"""
        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘
        lines = content.split('\n')
        description = ""
        tags = []
        
        for line in lines:
            if "æè¿°" in line or "description" in line.lower():
                description = line.split(':', 1)[-1].strip()
            elif "æ ‡ç­¾" in line or "tags" in line.lower() or "tag" in line.lower():
                # æå–æ ‡ç­¾
                tag_part = line.split(':', 1)[-1].strip()
                tags.extend([tag.strip() for tag in tag_part.split(',') if tag.strip()])
        
        return {
            "description": description or "AIåˆ†æçš„äººç‰©å§¿åŠ¿å›¾ç‰‡",
            "tags": tags[:10],
            "confidence": 0.8
        }
    
    def _get_fallback_analysis(self) -> Dict[str, Any]:
        """è·å–å¤‡ç”¨åˆ†æç»“æœ"""
        return {
            "description": "äººç‰©å§¿åŠ¿å‚è€ƒå›¾ç‰‡",
            "tags": ["äººç‰©", "å§¿åŠ¿", "å‚è€ƒ"],
            "confidence": 0.5
        }
    
    async def close(self):
        """å…³é—­HTTPå®¢æˆ·ç«¯"""
        await self.client.aclose()


# åˆ›å»ºå…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = AIService()