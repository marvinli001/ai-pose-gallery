"""
å°çº¢ä¹¦æ•°æ®æºæœåŠ¡
"""
import asyncio
import httpx
import json
import re
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import hashlib
from urllib.parse import urljoin, urlparse

from app.config import get_settings
from app.services.gpt4o_service import gpt4o_analyzer

settings = get_settings()


class XiaohongshuService:
    """å°çº¢ä¹¦æ•°æ®è·å–æœåŠ¡"""
    
    def __init__(self):
        self.client = httpx.AsyncClient(
            timeout=30,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
                'Accept-Encoding': 'gzip, deflate',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
        )
        
        # å°çº¢ä¹¦æœç´¢å…³é”®è¯åº“
        self.search_keywords = [
            "å§¿åŠ¿å‚è€ƒ", "poseå‚è€ƒ", "äººç‰©å§¿åŠ¿", "æ‹ç…§å§¿åŠ¿",
            "æ‘„å½±å§¿åŠ¿", "æ¨¡ç‰¹å§¿åŠ¿", "å†™çœŸå§¿åŠ¿", "äººåƒæ‘„å½±",
            "åå§¿å‚è€ƒ", "ç«™å§¿å‚è€ƒ", "èººå§¿å‚è€ƒ", "åŠ¨ä½œå‚è€ƒ",
            "å•†åŠ¡ç…§å§¿åŠ¿", "ä¼‘é—²ç…§å§¿åŠ¿", "èŒä¸šç…§å§¿åŠ¿",
            "è‰ºæœ¯ç…§å§¿åŠ¿", "ç”Ÿæ´»ç…§å§¿åŠ¿", "è¡—æ‹å§¿åŠ¿"
        ]
    
    async def search_pose_references(self, keyword: str, limit: int = 20) -> Dict[str, Any]:
        """æœç´¢å°çº¢ä¹¦å§¿åŠ¿å‚è€ƒå†…å®¹"""
        try:
            print(f"ğŸ” æœç´¢å°çº¢ä¹¦å†…å®¹: {keyword}")
            
            # æ¨¡æ‹Ÿæœç´¢APIè°ƒç”¨ï¼ˆå®é™…éœ€è¦çœŸå®çš„å°çº¢ä¹¦APIæˆ–çˆ¬è™«ï¼‰
            search_results = await self._simulate_search(keyword, limit)
            
            # ä½¿ç”¨GPT-4oåˆ†æå’Œè¿‡æ»¤å†…å®¹
            filtered_results = await self._filter_and_analyze_content(search_results, keyword)
            
            return {
                "success": True,
                "keyword": keyword,
                "total_found": len(search_results),
                "filtered_count": len(filtered_results),
                "results": filtered_results,
                "source": "xiaohongshu"
            }
            
        except Exception as e:
            print(f"âŒ å°çº¢ä¹¦æœç´¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "keyword": keyword,
                "results": []
            }
    
    async def _simulate_search(self, keyword: str, limit: int) -> List[Dict[str, Any]]:
        """æ¨¡æ‹Ÿå°çº¢ä¹¦æœç´¢ç»“æœï¼ˆå®é™…é¡¹ç›®ä¸­éœ€è¦æ›¿æ¢ä¸ºçœŸå®APIï¼‰"""
        # è¿™é‡Œæ¨¡æ‹Ÿè¿”å›å°çº¢ä¹¦æœç´¢ç»“æœ
        # åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œä½ éœ€è¦ï¼š
        # 1. ç”³è¯·å°çº¢ä¹¦å¼€æ”¾å¹³å°API
        # 2. æˆ–è€…ä½¿ç”¨åˆè§„çš„çˆ¬è™«æ–¹æ¡ˆ
        # 3. æˆ–è€…ä½¿ç”¨ç¬¬ä¸‰æ–¹æ•°æ®æœåŠ¡
        
        mock_results = []
        for i in range(min(limit, 10)):
            mock_results.append({
                "id": f"xhs_{hashlib.md5(f'{keyword}_{i}'.encode()).hexdigest()[:12]}",
                "title": f"{keyword}æ•™ç¨‹ç¬¬{i+1}æœŸ - å°çº¢ä¹¦ç”¨æˆ·",
                "description": f"åˆ†äº«{keyword}çš„å®ç”¨æŠ€å·§ï¼ŒåŒ…å«å¤šç§{keyword}ç¤ºä¾‹ï¼Œé€‚åˆæ–°æ‰‹å­¦ä¹ å‚è€ƒã€‚",
                "author": f"ç”¨æˆ·{i+1:03d}",
                "images": [
                    f"https://example.com/xhs_image_{i}_{j}.jpg" for j in range(3)
                ],
                "tags": [keyword, "å§¿åŠ¿", "å‚è€ƒ", "æ•™ç¨‹"],
                "like_count": 100 + i * 50,
                "comment_count": 20 + i * 5,
                "share_count": 10 + i * 2,
                "publish_time": (datetime.now() - timedelta(days=i)).isoformat(),
                "url": f"https://www.xiaohongshu.com/explore/{hashlib.md5(f'{keyword}_{i}'.encode()).hexdigest()}",
                "category": "lifestyle"
            })
        
        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await asyncio.sleep(0.5)
        
        return mock_results
    
    async def _filter_and_analyze_content(self, results: List[Dict[str, Any]], keyword: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨GPT-4oåˆ†æå’Œè¿‡æ»¤å°çº¢ä¹¦å†…å®¹"""
        if not results:
            return []
        
        try:
            # æ„å»ºåˆ†ææç¤ºè¯
            content_summary = []
            for i, result in enumerate(results[:10]):  # é™åˆ¶åˆ†ææ•°é‡
                content_summary.append(f"{i+1}. æ ‡é¢˜: {result['title']}\n   æè¿°: {result['description']}\n   æ ‡ç­¾: {', '.join(result['tags'])}")
            
            analysis_prompt = f"""ä½œä¸ºå†…å®¹åˆ†æä¸“å®¶ï¼Œè¯·åˆ†æè¿™äº›å°çº¢ä¹¦æœç´¢ç»“æœï¼Œåˆ¤æ–­å“ªäº›å†…å®¹çœŸæ­£é€‚åˆä½œä¸º"{keyword}"çš„å‚è€ƒèµ„æ–™ã€‚

æœç´¢å…³é”®è¯ï¼š{keyword}

å†…å®¹åˆ—è¡¨ï¼š
{chr(10).join(content_summary)}

è¯·åˆ†ææ¯ä¸ªå†…å®¹çš„ç›¸å…³æ€§ï¼Œå¹¶è¿”å›JSONæ ¼å¼ï¼š
{{
    "analysis": "æ•´ä½“åˆ†æç»“æœ",
    "relevant_items": [
        {{
            "index": 1,
            "relevance_score": 0.9,
            "reason": "ç›¸å…³æ€§åŸå› ",
            "suggested_tags": ["å»ºè®®çš„æ ‡ç­¾"],
            "quality_score": 0.8
        }}
    ],
    "filtering_summary": "è¿‡æ»¤æ€»ç»“"
}}"""

            # è°ƒç”¨GPT-4oè¿›è¡Œå†…å®¹åˆ†æ
            analysis_result = await gpt4o_analyzer._call_gpt4o_text_api(analysis_prompt)
            
            try:
                analysis_data = json.loads(analysis_result)
                relevant_items = analysis_data.get("relevant_items", [])
                
                # æ ¹æ®åˆ†æç»“æœè¿‡æ»¤å†…å®¹
                filtered_results = []
                for item in relevant_items:
                    index = item.get("index", 1) - 1
                    if 0 <= index < len(results) and item.get("relevance_score", 0) >= 0.6:
                        result = results[index].copy()
                        result.update({
                            "ai_relevance_score": item.get("relevance_score", 0),
                            "ai_quality_score": item.get("quality_score", 0),
                            "ai_analysis_reason": item.get("reason", ""),
                            "ai_suggested_tags": item.get("suggested_tags", []),
                            "filtered_by": "gpt-4o"
                        })
                        filtered_results.append(result)
                
                return filtered_results
                
            except json.JSONDecodeError:
                print("âŒ GPT-4oè¿”å›ç»“æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è¿‡æ»¤")
                return await self._basic_filter(results, keyword)
                
        except Exception as e:
            print(f"âŒ GPT-4oå†…å®¹åˆ†æå¤±è´¥: {e}")
            return await self._basic_filter(results, keyword)
    
    async def _basic_filter(self, results: List[Dict[str, Any]], keyword: str) -> List[Dict[str, Any]]:
        """åŸºç¡€å†…å®¹è¿‡æ»¤ï¼ˆä¸ä¾èµ–GPT-4oï¼‰"""
        filtered = []
        
        for result in results:
            # åŸºäºå…³é”®è¯å’Œäº’åŠ¨æ•°æ®çš„ç®€å•è¿‡æ»¤
            title_score = self._calculate_keyword_score(result.get("title", ""), keyword)
            desc_score = self._calculate_keyword_score(result.get("description", ""), keyword)
            
            # åŸºäºç‚¹èµæ•°çš„è´¨é‡è¯„åˆ†
            like_count = result.get("like_count", 0)
            quality_score = min(like_count / 1000, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
            
            total_score = (title_score + desc_score) / 2 + quality_score * 0.3
            
            if total_score >= 0.5:
                result.update({
                    "ai_relevance_score": total_score,
                    "ai_quality_score": quality_score,
                    "ai_analysis_reason": "åŸºäºå…³é”®è¯å’Œäº’åŠ¨æ•°æ®çš„åŸºç¡€è¯„åˆ†",
                    "ai_suggested_tags": [keyword],
                    "filtered_by": "basic"
                })
                filtered.append(result)
        
        return filtered
    
    def _calculate_keyword_score(self, text: str, keyword: str) -> float:
        """è®¡ç®—æ–‡æœ¬ä¸å…³é”®è¯çš„ç›¸å…³æ€§å¾—åˆ†"""
        if not text or not keyword:
            return 0.0
        
        text_lower = text.lower()
        keyword_lower = keyword.lower()
        
        # ç²¾ç¡®åŒ¹é…
        if keyword_lower in text_lower:
            return 1.0
        
        # éƒ¨åˆ†åŒ¹é…
        keyword_chars = set(keyword_lower)
        text_chars = set(text_lower)
        overlap = len(keyword_chars & text_chars)
        
        return overlap / len(keyword_chars) if keyword_chars else 0.0
    
    async def download_and_analyze_image(self, image_url: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸‹è½½å°çº¢ä¹¦å›¾ç‰‡å¹¶è¿›è¡ŒGPT-4oåˆ†æ"""
        try:
            # ä¸‹è½½å›¾ç‰‡
            response = await self.client.get(image_url)
            if response.status_code != 200:
                raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {response.status_code}")
            
            image_content = response.content
            
            # ä¸´æ—¶ä¿å­˜å›¾ç‰‡ç”¨äºåˆ†æ
            import tempfile
            import os
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
                temp_file.write(image_content)
                temp_path = temp_file.name
            
            try:
                # ä½¿ç”¨GPT-4oåˆ†æå›¾ç‰‡
                analysis_result = await gpt4o_analyzer.analyze_for_search(temp_path)
                
                if analysis_result.get("success"):
                    analysis = analysis_result["analysis"]
                    
                    return {
                        "success": True,
                        "image_url": image_url,
                        "file_size": len(image_content),
                        "analysis": analysis,
                        "context": context,
                        "source": "xiaohongshu"
                    }
                else:
                    raise Exception("GPT-4oåˆ†æå¤±è´¥")
                    
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    
        except Exception as e:
            print(f"âŒ å°çº¢ä¹¦å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "image_url": image_url
            }
    
    async def batch_import_content(self, keywords: List[str], limit_per_keyword: int = 10) -> Dict[str, Any]:
        """æ‰¹é‡å¯¼å…¥å°çº¢ä¹¦å†…å®¹"""
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡å¯¼å…¥å°çº¢ä¹¦å†…å®¹ï¼Œå…³é”®è¯: {keywords}")
        
        all_results = []
        import_stats = {
            "total_searched": 0,
            "total_found": 0,
            "total_filtered": 0,
            "success_count": 0,
            "error_count": 0,
            "keywords_processed": []
        }
        
        for keyword in keywords:
            try:
                print(f"ğŸ” å¤„ç†å…³é”®è¯: {keyword}")
                
                # æœç´¢å†…å®¹
                search_result = await self.search_pose_references(keyword, limit_per_keyword)
                
                if search_result.get("success"):
                    results = search_result.get("results", [])
                    
                    # æ›´æ–°ç»Ÿè®¡
                    import_stats["total_searched"] += 1
                    import_stats["total_found"] += search_result.get("total_found", 0)
                    import_stats["total_filtered"] += search_result.get("filtered_count", 0)
                    import_stats["success_count"] += len(results)
                    import_stats["keywords_processed"].append(keyword)
                    
                    # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    for result in results:
                        result["source_keyword"] = keyword
                        all_results.append(result)
                else:
                    import_stats["error_count"] += 1
                    print(f"âŒ å…³é”®è¯ {keyword} æœç´¢å¤±è´¥")
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                await asyncio.sleep(1)
                
            except Exception as e:
                import_stats["error_count"] += 1
                print(f"âŒ å¤„ç†å…³é”®è¯ {keyword} æ—¶å‡ºé”™: {e}")
        
        return {
            "success": True,
            "results": all_results,
            "stats": import_stats,
            "message": f"æ‰¹é‡å¯¼å…¥å®Œæˆï¼Œå…±å¤„ç† {len(keywords)} ä¸ªå…³é”®è¯ï¼Œè·å¾— {len(all_results)} ä¸ªç»“æœ"
        }
    
    async def close(self):
        """å…³é—­HTTPå®¢æˆ·ç«¯"""
        await self.client.aclose()


# åˆ›å»ºå…¨å±€å°çº¢ä¹¦æœåŠ¡å®ä¾‹
xiaohongshu_service = XiaohongshuService()