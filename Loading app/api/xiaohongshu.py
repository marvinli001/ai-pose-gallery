"""
å°çº¢ä¹¦æ•°æ®å¯¼å…¥API
"""
from fastapi import APIRouter, Depends, Query, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from typing import List, Optional
import json

from app.database import get_db
from app.services.xiaohongshu_service import xiaohongshu_service
from app.services.database_service import DatabaseService
from app.models.external_source import ExternalContent, ExternalImage

router = APIRouter()


async def process_xiaohongshu_import(keywords: List[str], limit_per_keyword: int, db_session_factory):
    """åå°ä»»åŠ¡ï¼šå¤„ç†å°çº¢ä¹¦å†…å®¹å¯¼å…¥"""
    try:
        print(f"ğŸ”„ å¼€å§‹å¤„ç†å°çº¢ä¹¦å¯¼å…¥ä»»åŠ¡")
        
        # æ‰¹é‡å¯¼å…¥å†…å®¹
        import_result = await xiaohongshu_service.batch_import_content(keywords, limit_per_keyword)
        
        if import_result.get("success"):
            results = import_result.get("results", [])
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            from app.database import SessionLocal
            db = SessionLocal()
            try:
                saved_count = 0
                for content_data in results:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(ExternalContent).filter(
                        ExternalContent.external_id == content_data.get("id"),
                        ExternalContent.source_platform == "xiaohongshu"
                    ).first()
                    
                    if not existing:
                        # åˆ›å»ºæ–°è®°å½•
                        external_content = ExternalContent(
                            external_id=content_data.get("id"),
                            source_platform="xiaohongshu",
                            source_url=content_data.get("url"),
                            title=content_data.get("title"),
                            description=content_data.get("description"),
                            author=content_data.get("author"),
                            category=content_data.get("category"),
                            image_urls=content_data.get("images", []),
                            like_count=content_data.get("like_count", 0),
                            comment_count=content_data.get("comment_count", 0),
                            share_count=content_data.get("share_count", 0),
                            ai_relevance_score=content_data.get("ai_relevance_score"),
                            ai_quality_score=content_data.get("ai_quality_score"),
                            ai_suggested_tags=content_data.get("ai_suggested_tags", []),
                            ai_analysis_reason=content_data.get("ai_analysis_reason"),
                            import_keyword=content_data.get("source_keyword"),
                            raw_data=content_data
                        )
                        
                        db.add(external_content)
                        saved_count += 1
                
                db.commit()
                print(f"âœ… å°çº¢ä¹¦å¯¼å…¥å®Œæˆï¼Œä¿å­˜äº† {saved_count} æ¡å†…å®¹")
                
            except Exception as e:
                print(f"âŒ ä¿å­˜å°çº¢ä¹¦å†…å®¹å¤±è´¥: {e}")
                db.rollback()
            finally:
                db.close()
        
    except Exception as e:
        print(f"âŒ å°çº¢ä¹¦å¯¼å…¥ä»»åŠ¡å¤±è´¥: {e}")


@router.post("/import")
async def import_xiaohongshu_content(
    background_tasks: BackgroundTasks,
    keywords: List[str] = Query(..., description="æœç´¢å…³é”®è¯åˆ—è¡¨"),
    limit_per_keyword: int = Query(10, ge=1, le=50, description="æ¯ä¸ªå…³é”®è¯çš„æœç´¢æ•°é‡"),
    db: Session = Depends(get_db)
):
    """å¯¼å…¥å°çº¢ä¹¦å†…å®¹"""
    try:
        # å¯åŠ¨åå°å¯¼å…¥ä»»åŠ¡
        background_tasks.add_task(
            process_xiaohongshu_import,
            keywords,
            limit_per_keyword,
            None  # ä¼ é€’æ•°æ®åº“å·¥å‚å‡½æ•°
        )
        
        return {
            "success": True,
            "message": f"å°çº¢ä¹¦å†…å®¹å¯¼å…¥ä»»åŠ¡å·²å¯åŠ¨ï¼Œå°†æœç´¢ {len(keywords)} ä¸ªå…³é”®è¯",
            "keywords": keywords,
            "limit_per_keyword": limit_per_keyword
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥ä»»åŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")


@router.get("/search")
async def search_xiaohongshu_content(
    keyword: str = Query(..., description="æœç´¢å…³é”®è¯"),
    limit: int = Query(20, ge=1, le=100, description="æœç´¢æ•°é‡"),
    analyze: bool = Query(True, description="æ˜¯å¦è¿›è¡ŒAIåˆ†æ")
):
    """å®æ—¶æœç´¢å°çº¢ä¹¦å†…å®¹"""
    try:
        result = await xiaohongshu_service.search_pose_references(keyword, limit)
        
        return {
            "success": True,
            "data": result
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


@router.get("/content")
async def get_external_content(
    page: int = Query(1, ge=1, description="é¡µç "),
    per_page: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    platform: str = Query("xiaohongshu", description="å¹³å°"),
    keyword: Optional[str] = Query(None, description="å¯¼å…¥å…³é”®è¯è¿‡æ»¤"),
    db: Session = Depends(get_db)
):
    """è·å–å·²å¯¼å…¥çš„å¤–éƒ¨å†…å®¹"""
    try:
        offset = (page - 1) * per_page
        
        # æ„å»ºæŸ¥è¯¢
        query = db.query(ExternalContent).filter(
            ExternalContent.source_platform == platform,
            ExternalContent.is_active == True
        )
        
        if keyword:
            query = query.filter(ExternalContent.import_keyword.contains(keyword))
        
        # è·å–æ€»æ•°
        total = query.count()
        
        # è·å–åˆ†é¡µæ•°æ®
        contents = query.order_by(
            ExternalContent.import_time.desc()
        ).offset(offset).limit(per_page).all()
        
        # æ ¼å¼åŒ–ç»“æœ
        result_contents = []
        for content in contents:
            result_contents.append({
                "id": content.id,
                "external_id": content.external_id,
                "title": content.title,
                "description": content.description,
                "author": content.author,
                "source_url": content.source_url,
                "image_urls": content.image_urls or [],
                "like_count": content.like_count,
                "comment_count": content.comment_count,
                "share_count": content.share_count,
                "ai_relevance_score": content.ai_relevance_score,
                "ai_quality_score": content.ai_quality_score,
                "ai_suggested_tags": content.ai_suggested_tags or [],
                "import_keyword": content.import_keyword,
                "import_time": content.import_time.isoformat() if content.import_time else None,
                "is_processed": content.is_processed
            })
        
        return {
            "success": True,
            "data": {
                "contents": result_contents,
                "pagination": {
                    "page": page,
                    "per_page": per_page,
                    "total": total,
                    "pages": (total + per_page - 1) // per_page
                }
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å†…å®¹å¤±è´¥: {str(e)}")


@router.get("/stats")
async def get_xiaohongshu_stats(db: Session = Depends(get_db)):
    """è·å–å°çº¢ä¹¦å¯¼å…¥ç»Ÿè®¡"""
    try:
        from sqlalchemy import func
        
        # åŸºç¡€ç»Ÿè®¡
        total_content = db.query(ExternalContent).filter(
            ExternalContent.source_platform == "xiaohongshu"
        ).count()
        
        active_content = db.query(ExternalContent).filter(
            ExternalContent.source_platform == "xiaohongshu",
            ExternalContent.is_active == True
        ).count()
        
        processed_content = db.query(ExternalContent).filter(
            ExternalContent.source_platform == "xiaohongshu",
            ExternalContent.is_processed == True
        ).count()
        
        # æŒ‰å…³é”®è¯ç»Ÿè®¡
        keyword_stats = db.query(
            ExternalContent.import_keyword,
            func.count(ExternalContent.id).label('count')
        ).filter(
            ExternalContent.source_platform == "xiaohongshu"
        ).group_by(ExternalContent.import_keyword).all()
        
        # è´¨é‡è¯„åˆ†ç»Ÿè®¡
        avg_relevance = db.query(
            func.avg(ExternalContent.ai_relevance_score)
        ).filter(
            ExternalContent.source_platform == "xiaohongshu",
            ExternalContent.ai_relevance_score.isnot(None)
        ).scalar() or 0
        
        avg_quality = db.query(
            func.avg(ExternalContent.ai_quality_score)
        ).filter(
            ExternalContent.source_platform == "xiaohongshu",
            ExternalContent.ai_quality_score.isnot(None)
        ).scalar() or 0
        
        return {
            "success": True,
            "data": {
                "total_content": total_content,
                "active_content": active_content,
                "processed_content": processed_content,
                "processing_rate": processed_content / total_content if total_content > 0 else 0,
                "avg_relevance_score": round(avg_relevance, 3),
                "avg_quality_score": round(avg_quality, 3),
                "keyword_distribution": [
                    {"keyword": kw, "count": count} for kw, count in keyword_stats
                ]
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.delete("/content/{content_id}")
async def delete_external_content(content_id: int, db: Session = Depends(get_db)):
    """åˆ é™¤å¤–éƒ¨å†…å®¹"""
    try:
        content = db.query(ExternalContent).filter(ExternalContent.id == content_id).first()
        
        if not content:
            raise HTTPException(status_code=404, detail="å†…å®¹ä¸å­˜åœ¨")
        
        # è½¯åˆ é™¤
        content.is_active = False
        db.commit()
        
        return {"success": True, "message": "å†…å®¹åˆ é™¤æˆåŠŸ"}
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")